{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTImAdNEi4lz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "AI Development Workflow: Hospital Readmission Prediction System\n",
        "Complete implementation from data preprocessing to deployment monitoring\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (confusion_matrix, classification_report,\n",
        "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
        "                             accuracy_score, precision_score, recall_score, f1_score)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "#==============================================================================\n",
        "# PART 1: DATA GENERATION (Simulating Hospital EHR Data)\n",
        "#==============================================================================\n",
        "\n",
        "def generate_synthetic_hospital_data(n_samples=5000):\n",
        "    \"\"\"\n",
        "    Generate synthetic patient data mimicking EHR system\n",
        "    Features include demographics, clinical measures, and social determinants\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"STEP 1: DATA GENERATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Demographics\n",
        "    age = np.random.normal(65, 15, n_samples).clip(18, 95)\n",
        "    gender = np.random.choice(['M', 'F'], n_samples, p=[0.48, 0.52])\n",
        "\n",
        "    # Clinical features\n",
        "    num_comorbidities = np.random.poisson(2.5, n_samples)\n",
        "    num_medications = np.random.poisson(5, n_samples)\n",
        "    length_of_stay = np.random.gamma(2, 2, n_samples).clip(1, 30)\n",
        "\n",
        "    # Lab values (with some missing data)\n",
        "    hemoglobin = np.random.normal(13, 2, n_samples).clip(7, 18)\n",
        "    creatinine = np.random.gamma(2, 0.5, n_samples).clip(0.5, 5)\n",
        "\n",
        "    # Social determinants\n",
        "    insurance = np.random.choice(['Medicare', 'Medicaid', 'Private', 'Uninsured'],\n",
        "                                 n_samples, p=[0.45, 0.20, 0.30, 0.05])\n",
        "    distance_to_hospital = np.random.exponential(15, n_samples).clip(1, 100)\n",
        "\n",
        "    # Prior utilization\n",
        "    prior_admissions = np.random.poisson(1, n_samples)\n",
        "    ed_visits_6mo = np.random.poisson(0.8, n_samples)\n",
        "\n",
        "    # Diagnosis categories (simplified)\n",
        "    diagnosis = np.random.choice(['Heart Failure', 'Pneumonia', 'COPD', 'Sepsis', 'Other'],\n",
        "                                 n_samples, p=[0.25, 0.20, 0.15, 0.10, 0.30])\n",
        "\n",
        "    # Discharge disposition\n",
        "    discharge_location = np.random.choice(['Home', 'SNF', 'Rehab', 'Home Health'],\n",
        "                                         n_samples, p=[0.60, 0.20, 0.10, 0.10])\n",
        "\n",
        "    # Target: 30-day readmission (influenced by risk factors)\n",
        "    risk_score = (\n",
        "        0.02 * age +\n",
        "        0.3 * num_comorbidities +\n",
        "        0.2 * num_medications +\n",
        "        0.1 * length_of_stay +\n",
        "        0.4 * prior_admissions +\n",
        "        0.3 * ed_visits_6mo +\n",
        "        -0.5 * (hemoglobin - 13) +\n",
        "        0.3 * creatinine +\n",
        "        0.01 * distance_to_hospital +\n",
        "        (insurance == 'Uninsured').astype(int) * 2 +\n",
        "        (diagnosis == 'Heart Failure').astype(int) * 1.5 +\n",
        "        np.random.normal(0, 2, n_samples)  # Random noise\n",
        "    )\n",
        "\n",
        "    # Convert risk score to probability and binary outcome\n",
        "    prob_readmit = 1 / (1 + np.exp(-risk_score + 5))\n",
        "    readmitted = (np.random.random(n_samples) < prob_readmit).astype(int)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'age': age,\n",
        "        'gender': gender,\n",
        "        'num_comorbidities': num_comorbidities,\n",
        "        'num_medications': num_medications,\n",
        "        'length_of_stay': length_of_stay,\n",
        "        'hemoglobin': hemoglobin,\n",
        "        'creatinine': creatinine,\n",
        "        'insurance': insurance,\n",
        "        'distance_to_hospital': distance_to_hospital,\n",
        "        'prior_admissions': prior_admissions,\n",
        "        'ed_visits_6mo': ed_visits_6mo,\n",
        "        'diagnosis': diagnosis,\n",
        "        'discharge_location': discharge_location,\n",
        "        'readmitted_30d': readmitted\n",
        "    })\n",
        "\n",
        "    # Introduce realistic missing data patterns\n",
        "    missing_indices = np.random.choice(n_samples, int(0.15 * n_samples), replace=False)\n",
        "    df.loc[missing_indices, 'hemoglobin'] = np.nan\n",
        "\n",
        "    missing_indices = np.random.choice(n_samples, int(0.10 * n_samples), replace=False)\n",
        "    df.loc[missing_indices, 'creatinine'] = np.nan\n",
        "\n",
        "    print(f\"‚úì Generated {n_samples} synthetic patient records\")\n",
        "    print(f\"‚úì Readmission rate: {df['readmitted_30d'].mean():.1%}\")\n",
        "    print(f\"‚úì Features: {df.shape[1] - 1} (excluding target)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "#==============================================================================\n",
        "# PART 2: EXPLORATORY DATA ANALYSIS\n",
        "#==============================================================================\n",
        "\n",
        "def perform_eda(df):\n",
        "    \"\"\"Comprehensive exploratory data analysis\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 2: EXPLORATORY DATA ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\n--- Data Overview ---\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\n--- Data Types and Missing Values ---\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\n--- Descriptive Statistics ---\")\n",
        "    print(df.describe())\n",
        "\n",
        "    print(\"\\n--- Target Distribution ---\")\n",
        "    print(df['readmitted_30d'].value_counts(normalize=True))\n",
        "\n",
        "    print(\"\\n--- Missing Data Analysis ---\")\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = 100 * missing / len(df)\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing_Count': missing,\n",
        "        'Percentage': missing_pct\n",
        "    })\n",
        "    print(missing_df[missing_df['Missing_Count'] > 0])\n",
        "\n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Age distribution by readmission\n",
        "    axes[0, 0].hist([df[df['readmitted_30d']==0]['age'],\n",
        "                     df[df['readmitted_30d']==1]['age']],\n",
        "                    bins=30, label=['Not Readmitted', 'Readmitted'], alpha=0.7)\n",
        "    axes[0, 0].set_xlabel('Age')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Age Distribution by Readmission Status')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # Readmission by diagnosis\n",
        "    diag_readmit = df.groupby('diagnosis')['readmitted_30d'].mean().sort_values()\n",
        "    axes[0, 1].barh(diag_readmit.index, diag_readmit.values, color='steelblue')\n",
        "    axes[0, 1].set_xlabel('Readmission Rate')\n",
        "    axes[0, 1].set_title('Readmission Rate by Diagnosis')\n",
        "\n",
        "    # Correlation heatmap (numeric features only)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    corr = df[numeric_cols].corr()\n",
        "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "                center=0, ax=axes[1, 0], cbar_kws={'shrink': 0.8})\n",
        "    axes[1, 0].set_title('Feature Correlation Matrix')\n",
        "\n",
        "    # Number of comorbidities vs readmission\n",
        "    comorbid_readmit = df.groupby('num_comorbidities')['readmitted_30d'].mean()\n",
        "    axes[1, 1].plot(comorbid_readmit.index, comorbid_readmit.values,\n",
        "                    marker='o', linewidth=2, markersize=8)\n",
        "    axes[1, 1].set_xlabel('Number of Comorbidities')\n",
        "    axes[1, 1].set_ylabel('Readmission Rate')\n",
        "    axes[1, 1].set_title('Readmission Rate by Comorbidity Count')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('eda_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n‚úì EDA visualizations saved to 'eda_analysis.png'\")\n",
        "\n",
        "#==============================================================================\n",
        "# PART 3: DATA PREPROCESSING\n",
        "#==============================================================================\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Comprehensive preprocessing pipeline:\n",
        "    - Handle missing values\n",
        "    - Feature engineering\n",
        "    - Encoding categorical variables\n",
        "    - Scaling numeric features\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 3: DATA PREPROCESSING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # 1. Feature Engineering\n",
        "    print(\"\\n--- Feature Engineering ---\")\n",
        "\n",
        "    # Create age groups\n",
        "    df_processed['age_group'] = pd.cut(df_processed['age'],\n",
        "                                       bins=[0, 50, 65, 80, 100],\n",
        "                                       labels=['<50', '50-65', '65-80', '80+'])\n",
        "\n",
        "    # Polypharmacy flag\n",
        "    df_processed['polypharmacy'] = (df_processed['num_medications'] >= 5).astype(int)\n",
        "\n",
        "    # High-risk comorbidity flag\n",
        "    df_processed['high_comorbidity'] = (df_processed['num_comorbidities'] >= 3).astype(int)\n",
        "\n",
        "    # Interaction features\n",
        "    df_processed['age_x_comorbid'] = df_processed['age'] * df_processed['num_comorbidities']\n",
        "\n",
        "    # Days since last admission (simulated)\n",
        "    df_processed['days_since_last_admit'] = np.where(\n",
        "        df_processed['prior_admissions'] > 0,\n",
        "        np.random.exponential(90, len(df_processed)),\n",
        "        365  # No prior admission\n",
        "    )\n",
        "\n",
        "    # Log transform skewed features\n",
        "    df_processed['log_length_of_stay'] = np.log1p(df_processed['length_of_stay'])\n",
        "    df_processed['log_distance'] = np.log1p(df_processed['distance_to_hospital'])\n",
        "\n",
        "    print(\"‚úì Created 8 engineered features\")\n",
        "\n",
        "    # 2. Handle Missing Values\n",
        "    print(\"\\n--- Handling Missing Values ---\")\n",
        "\n",
        "    # Impute numeric features with median\n",
        "    numeric_features = ['hemoglobin', 'creatinine']\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df_processed[numeric_features] = imputer.fit_transform(df_processed[numeric_features])\n",
        "\n",
        "    # Create missing indicators\n",
        "    for col in numeric_features:\n",
        "        df_processed[f'{col}_missing'] = df[col].isnull().astype(int)\n",
        "\n",
        "    print(f\"‚úì Imputed missing values in {len(numeric_features)} features\")\n",
        "    print(f\"‚úì Created {len(numeric_features)} missing indicators\")\n",
        "\n",
        "    # 3. Encode Categorical Variables\n",
        "    print(\"\\n--- Encoding Categorical Variables ---\")\n",
        "\n",
        "    # Binary encoding for gender\n",
        "    df_processed['gender_encoded'] = (df_processed['gender'] == 'M').astype(int)\n",
        "\n",
        "    # One-hot encoding for categorical features\n",
        "    categorical_features = ['insurance', 'diagnosis', 'discharge_location', 'age_group']\n",
        "    df_encoded = pd.get_dummies(df_processed, columns=categorical_features,\n",
        "                                 drop_first=True, dtype=int)\n",
        "\n",
        "    print(f\"‚úì One-hot encoded {len(categorical_features)} categorical features\")\n",
        "\n",
        "    # 4. Separate features and target\n",
        "    X = df_encoded.drop(['readmitted_30d', 'gender'], axis=1)\n",
        "    y = df_encoded['readmitted_30d']\n",
        "\n",
        "    print(f\"\\n‚úì Final feature set: {X.shape[1]} features\")\n",
        "    print(f\"‚úì Target distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "#==============================================================================\n",
        "# PART 4: MODEL DEVELOPMENT & TRAINING\n",
        "#==============================================================================\n",
        "\n",
        "def train_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train multiple models and compare performance\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 4: MODEL DEVELOPMENT & TRAINING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Handle class imbalance with SMOTE\n",
        "    print(\"\\n--- Handling Class Imbalance with SMOTE ---\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
        "    print(f\"Original training set: {y_train.value_counts().to_dict()}\")\n",
        "    print(f\"Balanced training set: {dict(zip(*np.unique(y_train_balanced, return_counts=True)))}\")\n",
        "\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10,\n",
        "                                                random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5,\n",
        "                                                         learning_rate=0.1, random_state=42)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n--- Training {name} ---\")\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "        # Evaluation metrics\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'accuracy': accuracy_score(y_test, y_pred),\n",
        "            'precision': precision_score(y_test, y_pred),\n",
        "            'recall': recall_score(y_test, y_pred),\n",
        "            'f1': f1_score(y_test, y_pred),\n",
        "            'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
        "            'y_pred': y_pred,\n",
        "            'y_pred_proba': y_pred_proba\n",
        "        }\n",
        "\n",
        "        print(f\"‚úì Accuracy:  {results[name]['accuracy']:.4f}\")\n",
        "        print(f\"‚úì Precision: {results[name]['precision']:.4f}\")\n",
        "        print(f\"‚úì Recall:    {results[name]['recall']:.4f}\")\n",
        "        print(f\"‚úì F1-Score:  {results[name]['f1']:.4f}\")\n",
        "        print(f\"‚úì ROC-AUC:   {results[name]['roc_auc']:.4f}\")\n",
        "\n",
        "    return results, scaler\n",
        "\n",
        "#==============================================================================\n",
        "# PART 5: MODEL EVALUATION\n",
        "#==============================================================================\n",
        "\n",
        "def evaluate_models(results, y_test):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with visualizations\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 5: MODEL EVALUATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Select best model (highest ROC-AUC)\n",
        "    best_model_name = max(results, key=lambda x: results[x]['roc_auc'])\n",
        "    best_result = results[best_model_name]\n",
        "\n",
        "    print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
        "    print(f\"   ROC-AUC: {best_result['roc_auc']:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"\\n--- Confusion Matrix ---\")\n",
        "    cm = confusion_matrix(y_test, best_result['y_pred'])\n",
        "    print(cm)\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"\\n--- Classification Report ---\")\n",
        "    print(classification_report(y_test, best_result['y_pred'],\n",
        "                                target_names=['No Readmission', 'Readmission']))\n",
        "\n",
        "    # Calculate specific metrics from confusion matrix\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(f\"\\nDetailed Metrics:\")\n",
        "    print(f\"True Negatives:  {tn}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "    print(f\"True Positives:  {tp}\")\n",
        "    print(f\"Specificity:     {tn/(tn+fp):.4f}\")\n",
        "    print(f\"Sensitivity:     {tp/(tp+fn):.4f}\")\n",
        "\n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "    # 1. Confusion Matrix Heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],\n",
        "                xticklabels=['No Readmit', 'Readmit'],\n",
        "                yticklabels=['No Readmit', 'Readmit'])\n",
        "    axes[0, 0].set_ylabel('Actual')\n",
        "    axes[0, 0].set_xlabel('Predicted')\n",
        "    axes[0, 0].set_title(f'Confusion Matrix - {best_model_name}')\n",
        "\n",
        "    # 2. ROC Curve\n",
        "    from sklearn.metrics import roc_curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, best_result['y_pred_proba'])\n",
        "    axes[0, 1].plot(fpr, tpr, linewidth=2,\n",
        "                    label=f'ROC (AUC = {best_result[\"roc_auc\"]:.3f})')\n",
        "    axes[0, 1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "    axes[0, 1].set_xlabel('False Positive Rate')\n",
        "    axes[0, 1].set_ylabel('True Positive Rate')\n",
        "    axes[0, 1].set_title('ROC Curve')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Precision-Recall Curve\n",
        "    precision, recall, _ = precision_recall_curve(y_test, best_result['y_pred_proba'])\n",
        "    axes[1, 0].plot(recall, precision, linewidth=2, color='green')\n",
        "    axes[1, 0].set_xlabel('Recall')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].set_title('Precision-Recall Curve')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Model Comparison\n",
        "    model_names = list(results.keys())\n",
        "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "\n",
        "    x = np.arange(len(model_names))\n",
        "    width = 0.15\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        values = [results[name][metric] for name in model_names]\n",
        "        axes[1, 1].bar(x + i*width, values, width, label=metric.upper())\n",
        "\n",
        "    axes[1, 1].set_xlabel('Models')\n",
        "    axes[1, 1].set_ylabel('Score')\n",
        "    axes[1, 1].set_title('Model Performance Comparison')\n",
        "    axes[1, 1].set_xticks(x + width * 2)\n",
        "    axes[1, 1].set_xticklabels(model_names, rotation=15, ha='right')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_evaluation.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n‚úì Evaluation visualizations saved to 'model_evaluation.png'\")\n",
        "\n",
        "    return best_model_name, best_result\n",
        "\n",
        "#==============================================================================\n",
        "# PART 6: HYPERPARAMETER TUNING\n",
        "#==============================================================================\n",
        "\n",
        "def hyperparameter_tuning(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Grid search for optimal hyperparameters\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 6: HYPERPARAMETER TUNING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Balance classes\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    # Define parameter grid for Random Forest\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 15],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    print(\"\\n--- Grid Search for Random Forest ---\")\n",
        "    print(f\"Parameter combinations to test: {np.prod([len(v) for v in param_grid.values()])}\")\n",
        "\n",
        "    # Perform grid search with cross-validation\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='roc_auc',\n",
        "                               n_jobs=-1, verbose=1)\n",
        "\n",
        "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "    print(f\"\\n‚úì Best Parameters: {grid_search.best_params_}\")\n",
        "    print(f\"‚úì Best ROC-AUC Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    return grid_search.best_estimator_, grid_search.best_params_\n",
        "\n",
        "#==============================================================================\n",
        "# PART 7: FAIRNESS ANALYSIS\n",
        "#==============================================================================\n",
        "\n",
        "def fairness_analysis(df, X_test, y_test, y_pred, y_pred_proba):\n",
        "    \"\"\"\n",
        "    Analyze model fairness across demographic groups\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 7: FAIRNESS & BIAS ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get original data for demographic analysis\n",
        "    test_indices = X_test.index\n",
        "    demographics = df.loc[test_indices, ['gender', 'insurance', 'age']].copy()\n",
        "    demographics['y_true'] = y_test.values\n",
        "    demographics['y_pred'] = y_pred\n",
        "    demographics['y_pred_proba'] = y_pred_proba\n",
        "\n",
        "    # Age stratification\n",
        "    demographics['age_group'] = pd.cut(demographics['age'],\n",
        "                                       bins=[0, 50, 65, 80, 100],\n",
        "                                       labels=['<50', '50-65', '65-80', '80+'])\n",
        "\n",
        "    print(\"\\n--- Fairness Metrics by Gender ---\")\n",
        "    for gender in demographics['gender'].unique():\n",
        "        subset = demographics[demographics['gender'] == gender]\n",
        "        print(f\"\\nGender: {gender}\")\n",
        "        print(f\"  Sample size: {len(subset)}\")\n",
        "        print(f\"  Precision:   {precision_score(subset['y_true'], subset['y_pred']):.4f}\")\n",
        "        print(f\"  Recall:      {recall_score(subset['y_true'], subset['y_pred']):.4f}\")\n",
        "        print(f\"  ROC-AUC:     {roc_auc_score(subset['y_true'], subset['y_pred_proba']):.4f}\")\n",
        "\n",
        "    print(\"\\n--- Fairness Metrics by Insurance Type ---\")\n",
        "    for insurance in demographics['insurance'].unique():\n",
        "        subset = demographics[demographics['insurance'] == insurance]\n",
        "        if len(subset) > 10:  # Only analyze if sufficient samples\n",
        "            print(f\"\\nInsurance: {insurance}\")\n",
        "            print(f\"  Sample size: {len(subset)}\")\n",
        "            print(f\"  Precision:   {precision_score(subset['y_true'], subset['y_pred']):.4f}\")\n",
        "            print(f\"  Recall:      {recall_score(subset['y_true'], subset['y_pred']):.4f}\")\n",
        "            print(f\"  ROC-AUC:     {roc_auc_score(subset['y_true'], subset['y_pred_proba']):.4f}\")\n",
        "\n",
        "    print(\"\\n--- Fairness Metrics by Age Group ---\")\n",
        "    for age_grp in demographics['age_group'].unique():\n",
        "        subset = demographics[demographics['age_group'] == age_grp]\n",
        "        print(f\"\\nAge Group: {age_grp}\")\n",
        "        print(f\"  Sample size: {len(subset)}\")\n",
        "        print(f\"  Precision:   {precision_score(subset['y_true'], subset['y_pred']):.4f}\")\n",
        "        print(f\"  Recall:      {recall_score(subset['y_true'], subset['y_pred']):.4f}\")\n",
        "        print(f\"  ROC-AUC:     {roc_auc_score(subset['y_true'], subset['y_pred_proba']):.4f}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Recall by insurance type\n",
        "    recall_by_insurance = demographics.groupby('insurance').apply(\n",
        "        lambda x: recall_score(x['y_true'], x['y_pred'])\n",
        "    ).sort_values()\n",
        "\n",
        "    axes[0].barh(recall_by_insurance.index, recall_by_insurance.values, color='coral')\n",
        "    axes[0].set_xlabel('Recall (Sensitivity)')\n",
        "    axes[0].set_title('Model Recall by Insurance Type')\n",
        "    axes[0].axvline(recall_by_insurance.mean(), color='red', linestyle='--',\n",
        "                    label=f'Mean: {recall_by_insurance.mean():.3f}')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Recall by age group\n",
        "    recall_by_age = demographics.groupby('age_group').apply(\n",
        "        lambda x: recall_score(x['y_true'], x['y_pred'])\n",
        "    )\n",
        "\n",
        "    axes[1].bar(recall_by_age.index, recall_by_age.values, color='skyblue')\n",
        "    axes[1].set_xlabel('Age Group')\n",
        "    axes[1].set_ylabel('Recall (Sensitivity)')\n",
        "    axes[1].set_title('Model Recall by Age Group')\n",
        "    axes[1].axhline(recall_by_age.mean(), color='red', linestyle='--',\n",
        "                    label=f'Mean: {recall_by_age.mean():.3f}')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('fairness_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n‚úì Fairness analysis visualizations saved to 'fairness_analysis.png'\")\n",
        "\n",
        "#==============================================================================\n",
        "# PART 8: DEPLOYMENT SIMULATION\n",
        "#==============================================================================\n",
        "\n",
        "def deployment_simulation(model, scaler, X_test, df):\n",
        "    \"\"\"\n",
        "    Simulate model deployment with risk stratification\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 8: DEPLOYMENT SIMULATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Scale test data\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Generate predictions\n",
        "    predictions = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Risk stratification\n",
        "    test_indices = X_test.index\n",
        "    deployment_df = df.loc[test_indices].copy()\n",
        "    deployment_df['risk_score'] = predictions\n",
        "    deployment_df['risk_category'] = pd.cut(predictions,\n",
        "                                            bins=[0, 0.3, 0.6, 1.0],\n",
        "                                            labels=['Low Risk', 'Moderate Risk', 'High Risk'])\n",
        "\n",
        "    print(\"\\n--- Risk Stratification ---\")\n",
        "    print(deployment_df['risk_category'].value_counts())\n",
        "\n",
        "    print(\"\\n--- Actual Readmission Rates by Risk Category ---\")\n",
        "    for category in ['Low Risk', 'Moderate Risk', 'High Risk']:\n",
        "        subset = deployment_df[deployment_df['risk_category'] == category]\n",
        "        if len(subset) > 0:\n",
        "            actual_rate = subset['readmitted_30d'].mean()\n",
        "            print(f\"{category}: {actual_rate:.2%} ({len(subset)} patients)\")\n",
        "\n",
        "    # Intervention recommendations\n",
        "    print(\"\\n--- Recommended Interventions ---\")\n",
        "    high_risk = deployment_df[deployment_df['risk_category'] == 'High Risk']\n",
        "    print(f\"High Risk Patients: {len(high_risk)}\")\n",
        "    print(\"  ‚Üí Schedule within 48 hours: Home health visit\")\n",
        "    print(\"  ‚Üí Within 7 days: Primary care follow-up\")\n",
        "    print(\"  ‚Üí Daily: Automated medication reminder calls\")\n",
        "\n",
        "    moderate_risk = deployment_df[deployment_df['risk_category'] == 'Moderate Risk']\n",
        "    print(f\"\\nModerate Risk Patients: {len(moderate_risk)}\")\n",
        "    print(\"  ‚Üí Within 14 days: Telehealth follow-up\")\n",
        "    print(\"  ‚Üí Weekly: Symptom monitoring calls\")\n",
        "\n",
        "    # Sample high-risk patient profile\n",
        "    print(\"\\n--- Sample High-Risk Patient Profile ---\")\n",
        "    sample_patient = high_risk.iloc[0]\n",
        "    print(f\"Age: {sample_patient['age']:.0f}\")\n",
        "    print(f\"Diagnosis: {sample_patient['diagnosis']}\")\n",
        "    print(f\"Comorbidities: {sample_patient['num_comorbidities']:.0f}\")\n",
        "    print(f\"Medications: {sample_patient['num_medications']:.0f}\")\n",
        "    print(f\"Prior Admissions: {sample_patient['prior_admissions']:.0f}\")\n",
        "    print(f\"Risk Score: {sample_patient['risk_score']:.2%}\")\n",
        "\n",
        "    return deployment_df\n",
        "\n",
        "#==============================================================================\n",
        "# PART 9: MONITORING & DRIFT DETECTION\n",
        "#==============================================================================\n",
        "\n",
        "def monitor_model_performance(deployment_df, window_size=100):\n",
        "    \"\"\"\n",
        "    Simulate post-deployment monitoring and concept drift detection\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 9: POST-DEPLOYMENT MONITORING\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Simulate time series of predictions\n",
        "    deployment_df = deployment_df.sort_index()\n",
        "    deployment_df['prediction_time'] = range(len(deployment_df))\n",
        "\n",
        "    # Calculate rolling metrics\n",
        "    deployment_df['rolling_accuracy'] = deployment_df.apply(\n",
        "        lambda x: (x['risk_score'] > 0.5) == x['readmitted_30d'], axis=1\n",
        "    ).rolling(window=window_size).mean()\n",
        "\n",
        "    # Feature distribution monitoring\n",
        "    print(\"\\n--- Feature Distribution Monitoring ---\")\n",
        "    print(f\"Mean age (current): {deployment_df['age'].mean():.1f}\")\n",
        "    print(f\"Mean comorbidities (current): {deployment_df['num_comorbidities'].mean():.2f}\")\n",
        "    print(f\"Mean length of stay (current): {deployment_df['length_of_stay'].mean():.2f}\")\n",
        "\n",
        "    # Simulate drift detection\n",
        "    print(\"\\n--- Concept Drift Detection ---\")\n",
        "\n",
        "    # Calculate prediction distribution drift\n",
        "    early_predictions = deployment_df.iloc[:len(deployment_df)//2]['risk_score']\n",
        "    late_predictions = deployment_df.iloc[len(deployment_df)//2:]['risk_score']\n",
        "\n",
        "    from scipy import stats\n",
        "    ks_statistic, p_value = stats.ks_2samp(early_predictions, late_predictions)\n",
        "\n",
        "    print(f\"KS Test Statistic: {ks_statistic:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    if p_value < 0.05:\n",
        "        print(\"‚ö†Ô∏è  WARNING: Significant distribution shift detected!\")\n",
        "        print(\"   Recommendation: Schedule model retraining\")\n",
        "    else:\n",
        "        print(\"‚úì No significant drift detected\")\n",
        "\n",
        "    # Performance degradation monitoring\n",
        "    print(\"\\n--- Performance Metrics Over Time ---\")\n",
        "    batches = np.array_split(deployment_df, 5)\n",
        "\n",
        "    for i, batch in enumerate(batches):\n",
        "        y_true = batch['readmitted_30d']\n",
        "        y_pred = (batch['risk_score'] > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "\n",
        "        print(f\"Batch {i+1}: Accuracy={accuracy:.4f}, Recall={recall:.4f}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # 1. Rolling accuracy over time\n",
        "    axes[0, 0].plot(deployment_df['prediction_time'],\n",
        "                    deployment_df['rolling_accuracy'], linewidth=2)\n",
        "    axes[0, 0].set_xlabel('Prediction Number')\n",
        "    axes[0, 0].set_ylabel(f'Rolling Accuracy (window={window_size})')\n",
        "    axes[0, 0].set_title('Model Performance Over Time')\n",
        "    axes[0, 0].axhline(y=0.75, color='r', linestyle='--', label='Target: 75%')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Risk score distribution over time\n",
        "    axes[0, 1].hist([early_predictions, late_predictions],\n",
        "                    bins=30, label=['Early Predictions', 'Late Predictions'],\n",
        "                    alpha=0.7)\n",
        "    axes[0, 1].set_xlabel('Risk Score')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].set_title('Risk Score Distribution: Early vs Late')\n",
        "    axes[0, 1].legend()\n",
        "\n",
        "    # 3. Feature drift: Age distribution\n",
        "    early_age = deployment_df.iloc[:len(deployment_df)//2]['age']\n",
        "    late_age = deployment_df.iloc[len(deployment_df)//2:]['age']\n",
        "\n",
        "    axes[1, 0].hist([early_age, late_age], bins=30,\n",
        "                    label=['Early Period', 'Late Period'], alpha=0.7)\n",
        "    axes[1, 0].set_xlabel('Age')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].set_title('Feature Drift: Age Distribution')\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "    # 4. Calibration plot\n",
        "    from sklearn.calibration import calibration_curve\n",
        "\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        deployment_df['readmitted_30d'],\n",
        "        deployment_df['risk_score'],\n",
        "        n_bins=10\n",
        "    )\n",
        "\n",
        "    axes[1, 1].plot(mean_predicted_value, fraction_of_positives,\n",
        "                    marker='o', linewidth=2, label='Model')\n",
        "    axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "    axes[1, 1].set_xlabel('Mean Predicted Probability')\n",
        "    axes[1, 1].set_ylabel('Fraction of Positives')\n",
        "    axes[1, 1].set_title('Calibration Curve')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('monitoring_drift.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n‚úì Monitoring visualizations saved to 'monitoring_drift.png'\")\n",
        "\n",
        "#==============================================================================\n",
        "# PART 10: FEATURE IMPORTANCE ANALYSIS\n",
        "#==============================================================================\n",
        "\n",
        "def feature_importance_analysis(model, X_train):\n",
        "    \"\"\"\n",
        "    Analyze and visualize feature importance for model interpretability\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 10: FEATURE IMPORTANCE ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get feature importance\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "        feature_names = X_train.columns\n",
        "\n",
        "        # Create DataFrame for sorting\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': importances\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(\"\\n--- Top 15 Most Important Features ---\")\n",
        "        print(importance_df.head(15).to_string(index=False))\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "        # Top 15 features bar plot\n",
        "        top_features = importance_df.head(15)\n",
        "        axes[0].barh(range(len(top_features)), top_features['importance'])\n",
        "        axes[0].set_yticks(range(len(top_features)))\n",
        "        axes[0].set_yticklabels(top_features['feature'])\n",
        "        axes[0].set_xlabel('Importance Score')\n",
        "        axes[0].set_title('Top 15 Feature Importances')\n",
        "        axes[0].invert_yaxis()\n",
        "\n",
        "        # Cumulative importance\n",
        "        importance_df['cumulative_importance'] = importance_df['importance'].cumsum()\n",
        "        axes[1].plot(range(len(importance_df)),\n",
        "                     importance_df['cumulative_importance'],\n",
        "                     linewidth=2, marker='o', markersize=3)\n",
        "        axes[1].axhline(y=0.90, color='r', linestyle='--',\n",
        "                       label='90% Cumulative Importance')\n",
        "        axes[1].set_xlabel('Number of Features')\n",
        "        axes[1].set_ylabel('Cumulative Importance')\n",
        "        axes[1].set_title('Cumulative Feature Importance')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "        print(\"\\n‚úì Feature importance visualizations saved to 'feature_importance.png'\")\n",
        "\n",
        "        return importance_df\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Model does not support feature importance\")\n",
        "        return None\n",
        "\n",
        "#==============================================================================\n",
        "# PART 11: COST-BENEFIT ANALYSIS\n",
        "#==============================================================================\n",
        "\n",
        "def cost_benefit_analysis(y_test, y_pred, y_pred_proba):\n",
        "    \"\"\"\n",
        "    Analyze financial impact of model deployment\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STEP 11: COST-BENEFIT ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Cost assumptions (in dollars)\n",
        "    READMISSION_COST = 15000  # Average cost of 30-day readmission\n",
        "    INTERVENTION_COST = 500   # Cost of post-discharge intervention\n",
        "    FALSE_ALARM_COST = 200    # Cost of unnecessary intervention\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    print(\"\\n--- Financial Impact Analysis ---\")\n",
        "\n",
        "    # Without model (no interventions)\n",
        "    total_readmissions_baseline = (tp + fn)\n",
        "    baseline_cost = total_readmissions_baseline * READMISSION_COST\n",
        "\n",
        "    print(f\"\\nBaseline (No Model):\")\n",
        "    print(f\"  Total readmissions: {total_readmissions_baseline}\")\n",
        "    print(f\"  Total cost: ${baseline_cost:,.2f}\")\n",
        "\n",
        "    # With model (assuming 50% intervention effectiveness)\n",
        "    INTERVENTION_EFFECTIVENESS = 0.50\n",
        "    prevented_readmissions = tp * INTERVENTION_EFFECTIVENESS\n",
        "    remaining_readmissions = tp * (1 - INTERVENTION_EFFECTIVENESS) + fn\n",
        "\n",
        "    intervention_costs = (tp + fp) * INTERVENTION_COST\n",
        "    readmission_costs = remaining_readmissions * READMISSION_COST\n",
        "    total_cost_with_model = intervention_costs + readmission_costs\n",
        "\n",
        "    print(f\"\\nWith Model:\")\n",
        "    print(f\"  Interventions provided: {tp + fp}\")\n",
        "    print(f\"  Prevented readmissions: {prevented_readmissions:.0f}\")\n",
        "    print(f\"  Remaining readmissions: {remaining_readmissions:.0f}\")\n",
        "    print(f\"  Intervention costs: ${intervention_costs:,.2f}\")\n",
        "    print(f\"  Readmission costs: ${readmission_costs:,.2f}\")\n",
        "    print(f\"  Total cost: ${total_cost_with_model:,.2f}\")\n",
        "\n",
        "    # Net benefit\n",
        "    net_savings = baseline_cost - total_cost_with_model\n",
        "    roi = (net_savings / intervention_costs) * 100\n",
        "\n",
        "    print(f\"\\nüí∞ Net Savings: ${net_savings:,.2f}\")\n",
        "    print(f\"üìà ROI: {roi:.1f}%\")\n",
        "\n",
        "    # Cost per patient\n",
        "    cost_per_patient_baseline = baseline_cost / len(y_test)\n",
        "    cost_per_patient_with_model = total_cost_with_model / len(y_test)\n",
        "\n",
        "    print(f\"\\nPer Patient Analysis:\")\n",
        "    print(f\"  Cost without model: ${cost_per_patient_baseline:,.2f}\")\n",
        "    print(f\"  Cost with model: ${cost_per_patient_with_model:,.2f}\")\n",
        "    print(f\"  Savings per patient: ${cost_per_patient_baseline - cost_per_patient_with_model:,.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Cost comparison\n",
        "    categories = ['Baseline\\n(No Model)', 'With Model']\n",
        "    costs = [baseline_cost, total_cost_with_model]\n",
        "    colors = ['#ff6b6b', '#4ecdc4']\n",
        "\n",
        "    bars = axes[0].bar(categories, costs, color=colors, alpha=0.7)\n",
        "    axes[0].set_ylabel('Total Cost ($)')\n",
        "    axes[0].set_title('Total Cost Comparison')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, cost in zip(bars, costs):\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'${cost:,.0f}',\n",
        "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Savings annotation\n",
        "    axes[0].annotate('', xy=(1, baseline_cost), xytext=(1, total_cost_with_model),\n",
        "                    arrowprops=dict(arrowstyle='<->', color='green', lw=2))\n",
        "    axes[0].text(1.15, (baseline_cost + total_cost_with_model)/2,\n",
        "                f'Savings:\\n${net_savings:,.0f}',\n",
        "                fontsize=11, color='green', fontweight='bold')\n",
        "\n",
        "    # Cost breakdown with model\n",
        "    breakdown_labels = ['Interventions', 'Remaining\\nReadmissions']\n",
        "    breakdown_values = [intervention_costs, readmission_costs]\n",
        "    breakdown_colors = ['#95e1d3', '#f38181']\n",
        "\n",
        "    wedges, texts, autotexts = axes[1].pie(breakdown_values, labels=breakdown_labels,\n",
        "                                            colors=breakdown_colors, autopct='%1.1f%%',\n",
        "                                            startangle=90)\n",
        "    axes[1].set_title('Cost Breakdown With Model')\n",
        "\n",
        "    # Make percentage text bold\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('cost_benefit_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n‚úì Cost-benefit analysis saved to 'cost_benefit_analysis.png'\")\n",
        "\n",
        "#==============================================================================\n",
        "# MAIN EXECUTION PIPELINE\n",
        "#==============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Execute complete AI development workflow\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" \"*20 + \"HOSPITAL READMISSION PREDICTION SYSTEM\")\n",
        "    print(\" \"*25 + \"Complete AI Workflow Pipeline\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Step 1: Generate synthetic data\n",
        "    df = generate_synthetic_hospital_data(n_samples=5000)\n",
        "\n",
        "    # Step 2: Exploratory Data Analysis\n",
        "    perform_eda(df)\n",
        "\n",
        "    # Step 3: Data Preprocessing\n",
        "    X, y = preprocess_data(df)\n",
        "\n",
        "    # Step 4: Train-Test Split (Time-aware)\n",
        "    print(\"\\n--- Train-Test Split ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.20, random_state=42, stratify=y\n",
        "    )\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Test set: {len(X_test)} samples\")\n",
        "\n",
        "    # Step 5: Model Training\n",
        "    results, scaler = train_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Step 6: Model Evaluation\n",
        "    best_model_name, best_result = evaluate_models(results, y_test)\n",
        "\n",
        "    # Step 7: Hyperparameter Tuning\n",
        "    tuned_model, best_params = hyperparameter_tuning(X_train, y_train)\n",
        "\n",
        "    # Step 8: Fairness Analysis\n",
        "    fairness_analysis(df, X_test, y_test,\n",
        "                     best_result['y_pred'],\n",
        "                     best_result['y_pred_proba'])\n",
        "\n",
        "    # Step 9: Feature Importance\n",
        "    feature_importance_analysis(results[best_model_name]['model'], X_train)\n",
        "\n",
        "    # Step 10: Deployment Simulation\n",
        "    deployment_df = deployment_simulation(results[best_model_name]['model'],\n",
        "                                         scaler, X_test, df)\n",
        "\n",
        "    # Step 11: Monitoring\n",
        "    monitor_model_performance(deployment_df)\n",
        "\n",
        "    # Step 12: Cost-Benefit Analysis\n",
        "    cost_benefit_analysis(y_test, best_result['y_pred'],\n",
        "                         best_result['y_pred_proba'])\n",
        "\n",
        "    # Final Summary\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" \"*30 + \"WORKFLOW COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nüìä Generated Outputs:\")\n",
        "    print(\"  1. eda_analysis.png - Exploratory data analysis visualizations\")\n",
        "    print(\"  2. model_evaluation.png - Model performance metrics and comparisons\")\n",
        "    print(\"  3. fairness_analysis.png - Bias and fairness analysis across demographics\")\n",
        "    print(\"  4. feature_importance.png - Key predictive features\")\n",
        "    print(\"  5. monitoring_drift.png - Post-deployment monitoring and drift detection\")\n",
        "    print(\"  6. cost_benefit_analysis.png - Financial impact analysis\")\n",
        "\n",
        "    print(\"\\nüéØ Key Findings:\")\n",
        "    print(f\"  ‚Ä¢ Best Model: {best_model_name}\")\n",
        "    print(f\"  ‚Ä¢ ROC-AUC Score: {best_result['roc_auc']:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Recall (Sensitivity): {best_result['recall']:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Precision: {best_result['precision']:.4f}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Next Steps:\")\n",
        "    print(\"  1. Present findings to clinical stakeholders\")\n",
        "    print(\"  2. Conduct prospective validation study\")\n",
        "    print(\"  3. Develop integration plan with EHR system\")\n",
        "    print(\"  4. Establish monitoring dashboard\")\n",
        "    print(\"  5. Create clinician training materials\")\n",
        "    print(\"  6. Implement feedback loop for continuous improvement\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Execute the pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}